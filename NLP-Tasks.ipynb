{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a350755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
      "     -------------------------------------- 358.9/358.9 kB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73ef3d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\shahid.iqbal\\appdata\\local\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1923cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shahid.iqbal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99865ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import emoji\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score,fbeta_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30f4f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test data from Excel files\n",
    "\n",
    "train_data = pd.read_excel('G:/Desktop 1/HSE/Teaching/Fall 2023/Neural Network and Deep Learning/Lecture Slides/eng-train.xlsx')\n",
    "test_data = pd.read_excel('G:/Desktop 1/HSE/Teaching/Fall 2023/Neural Network and Deep Learning/Lecture Slides/eng-test.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ea97c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and all off you die</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck them all the world is better off without ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>death to zionist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we will exterminate these racists vermines so ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>muslims should be deported from europe before ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                                and all off you die      1\n",
       "1  fuck them all the world is better off without ...      1\n",
       "2                                   death to zionist      1\n",
       "3  we will exterminate these racists vermines so ...      1\n",
       "4  muslims should be deported from europe before ...      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5f37ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fuck that towelhead muslim kill obama and all ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bring back at keyboard hitler to sort this issue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bro go kill yooyourself your probably a sad ye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you will suffer after you dying</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fuck that jew bitch europe will not survive eu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  fuck that towelhead muslim kill obama and all ...      1\n",
       "1   bring back at keyboard hitler to sort this issue      0\n",
       "2  bro go kill yooyourself your probably a sad ye...      1\n",
       "3                    you will suffer after you dying      1\n",
       "4  fuck that jew bitch europe will not survive eu...      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d4810a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    872\n",
       "0     58\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target classes in train file\n",
    "\n",
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a121140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    243\n",
       "0     16\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target classes in test file\n",
    "\n",
    "test_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dea39bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values in train file\n",
    "\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb8f10f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values in test file\n",
    "\n",
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c564e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "#1) Removal of all the hashtags, HTML tags, mentions, punctuations, and URLs.\n",
    "#2) Changing to lowercase (for case sensitive languages)\n",
    "#3) Replace emojis with corresponding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fed8377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a pre-processing function\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Removal of hashtags, HTML tags, mentions, punctuations, and URLs\n",
    "    text = re.sub(r'#\\w+', '', text)             # Remove hashtags\n",
    "    text = re.sub(r'<.*?>', '', text)            # Remove HTML tags\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)   # Remove mentions numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)          # Remove punctuations\n",
    "    text = re.sub(r'http\\S+', '', text)          # Remove URLs\n",
    "    \n",
    "    \n",
    "    # Changing to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace emoji with corresponding text representation\n",
    "    text = emoji.demojize(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7ec795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  and all off you die\n",
       "1    fuck them all the world is better off without ...\n",
       "2                                     death to zionist\n",
       "3    we will exterminate these racists vermines so ...\n",
       "4    muslims should be deported from europe before ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply Pre-processing\n",
    "train_data['text']= train_data['text'].apply(lambda x: preprocess_text(x))\n",
    "train_data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c70cc101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fuck that towelhead muslim kill obama and all ...\n",
       "1     bring back at keyboard hitler to sort this issue\n",
       "2    bro go kill yooyourself your probably a sad ye...\n",
       "3                      you will suffer after you dying\n",
       "4    fuck that jew bitch europe will not survive eu...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['text']= test_data['text'].apply(lambda x: preprocess_text(x))\n",
    "test_data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e89b3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the stop word list\n",
    "stop_words_list = set(stopwords.words('english')) \n",
    "\n",
    "# define the function\n",
    "def remove_stop_words(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words_list]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dc495ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>die</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck world better without shit country know ki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>death zionist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exterminate racists vermines easily</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>muslims deported europe late</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                                                die      1\n",
       "1  fuck world better without shit country know ki...      1\n",
       "2                                      death zionist      1\n",
       "3                exterminate racists vermines easily      1\n",
       "4                       muslims deported europe late      1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'] = train_data['text'].apply(remove_stop_words)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97262b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fuck towelhead muslim kill obama othe muslim f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bring back keyboard hitler sort issue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bro go kill yooyourself probably sad year old ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suffer dying</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fuck jew bitch europe survive europe fine jewd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  fuck towelhead muslim kill obama othe muslim f...      1\n",
       "1              bring back keyboard hitler sort issue      0\n",
       "2  bro go kill yooyourself probably sad year old ...      1\n",
       "3                                       suffer dying      1\n",
       "4  fuck jew bitch europe survive europe fine jewd...      1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['text'] = test_data['text'].apply(remove_stop_words)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0fb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF weighting scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f83e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(ngram_range=(1,1))\n",
    "train_features = tv.fit_transform(train_data['text'])\n",
    "test_features = tv.transform(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58b13b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_features\n",
    "y_train = train_data['label']\n",
    "X_test  = test_features\n",
    "y_test  = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31616fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((930, 2239), (259, 2239))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9fd18b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest Result\n",
      "RFC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.2500    0.3636        16\n",
      "           1     0.9526    0.9918    0.9718       243\n",
      "\n",
      "    accuracy                         0.9459       259\n",
      "   macro avg     0.8096    0.6209    0.6677       259\n",
      "weighted avg     0.9349    0.9459    0.9342       259\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  4  12]\n",
      " [  2 241]]\n",
      "True Positives (TP): 241\n",
      "True Negatives (TN): 4\n",
      "False Positives (FP): 12\n",
      "False Negatives (FN): 2\n"
     ]
    }
   ],
   "source": [
    "# uni-gram\n",
    "# Set the random seed for reproducibility\n",
    "random_seed = 42\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print(\"Random Forest Result\")\n",
    "rfc = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=10,random_state=52)\n",
    "pred = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"RFC\")\n",
    "print(classification_report(y_test,pred,digits=4))\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "# Extracting TP, TN, FP, and FN\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56f970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
